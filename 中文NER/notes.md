# 中文NER
命名实体识别（NER）是信息提取的基本任务。

目前英文NER的最先进水平是使用LSTM-CRF模型结合集成了字符信息的单词表达式。

中文NER的一种直接方法是先进行单词细分（易产生分词错误），然后进行单词序列标记。

从目前来看，对于中文NER来说，基于字的方法比基于词的方法效果好。

## ACL2018《Chinese NER Using Lattice LSTM》
[源代码和数据](https://github.com/jiesutd/LatticeLSTM)

### 大体思想：网格结构的LSTM-CRF模型
+ 不仅编码输入的字序列，而且对所有与词典匹配的词也进行编码
+ 通过网格结构的LSTM将句子中与词典匹配的词表示出来，从而将潜在词信息集成到基于字的LSTM-CRF中
+ 使用网格结构的LSTM来自动控制信息从句子的开头流向末尾
+ 使用门控递归单元来选择句子中最相关的字和词

### 优点
不会出现分词错误。

### 缺点
结构较为复杂，速度慢

难以迁移到其他神经网络模型

### 结果
用多个不同领域的数据集进行测试，结果比仅基于字的LSTM和仅基于词的LSTM的效果都要好，并有较强的鲁棒性。

### 模型
+ 主网络结构为LSTM-CRF
+ BIOES标注模式
  
  `LabelSet = {O, B-PER, I-PER, E-PER, S-PER, B-LOC, I-LOC, E-LOC, S-LOC, B-ORG, I-ORG, E-ORG, S-ORG}`
  + B，即Begin，表示开始
  + I，即Intermediate，表示中间
  + E，即End，表示结尾
  + S，即Single，表示单个字符
  + O，即Other，表示其他，用于标记无关字符
  + PER代表人名， LOC代表位置， ORG代表组织
+ 基于字的模型
  
  将字序列输入LSTM-CRF模型

  字 -> 字符向量 -> 双向LSTM -> CRF -> 序列标注
  + 字符向量 + 双字词组向量
  + 字符向量 + 分词标注向量
  
  分词标注向量采用BMES标注方式进行处理。其中B表示Begin即识别出边界，M表示Middle即识别出实体中间名，E表示End即实体名识别介绍，S表示Single表示独立成词
+ 基于词的模型
  
  词 -> 词向量 -> 双向LSTM

  拼接所得的两组隐层状态即为词的表示
  **集成字的表示**
  词向量 + 字符表示

  字符表示：

  + 用双向LSTM学习词中的每一个字
  + 用LSTM分别从正、反方向学习词中的每一个字再集成在一起
  + 用标准CNN来获得词中的字符序列表示
+ 网格模型
  
  可以看作基于字的模型 + 基于词的单元 + 控制信息流向的门

  + 参数：输入向量，输出隐层向量，单元向量，门向量
  + 基本递归LSTM函数（11）

### 实验
#### 实验配置
+ 数据集分割
+ 词向量化
+ 超参数设置
#### 实验结果
P - 精确率

R - 召回率

F1 - P 和 R 的调和平均，当 F1 较高时，模型的性能越好

## ACL2020《Simplify the Usage of Lexicon in Chinese NER》
 提出了一个更简单而有效的将词信息加入字符表示的方法：将每个字符匹配的所有词加入基于字符的NER模型。
 ### 优点
 + 避免设计复杂的序列模型结构
 + 对于任意神经元NER模型来说，只需要对字符表示层做细微的调整即可引入词典信息
 + 速度快，性能好
 + 可以用在预训练模型中（如BERT）
### 结果
在四个中文NER数据集上进行测试，用单层双向 LSTM 实现序列模型层时，此方法可以在速度和表现两方面较最先进水平均有所提升。
### 方法（SoftLexiocon）
字符 -> 稠密的向量 -> 将SoftLexicon特征加入字符表示 -> 序列建模层 -> CRF层

#### 字符表示层
每个字符用一个稠密的向量表示

+ 字符 + 双字词语

#### 合并字典信息
+ 扩展的Softword（ExSoftword）
  
  用一个五维向量保留所有可能的分词结果

  缺点：
  + 不能得到预训练的单词矢量表示
  + 损失了一些匹配信息，不能分辨哪一个是要储存的正确结果
+ SoftLexicon
  + 对匹配的词进行分类（BMES）
  + 压缩词语集为固定维数的向量
    压缩词语集：
    + 平均池化
    + 加权算法（词语出现频率）
  + 和字符表示相结合
    结合四个词语集的表示为固定维数的向量 -> 加入每个字符的表示（连接）

#### 序列建模层
对字符之间的依赖关系进行建模，如使用双向LSTM，CNN，transformer

#### 标注推断层
CRF

### 实验
大多数设置与 Lattice-LSTM 相同，包括预训练的词向量、测试数据集、比较基准、评估度量等